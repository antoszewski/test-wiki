{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chem 373 - Module 1: 2D Ising Model and Phase Transitions\n",
    "## Due Date: Tuesday, 4/16/19\n",
    "\n",
    "In this module you will use the 2D Ising model to investigate some of the phase change behavior you have been talking about in class. This notebook will provide advice as to setting up the simulation and visualizing results, but will not do the coding for you. Remember, if you are stuck on a certain coding problem, Google (and StackExchange) are your friends! Throughout the module, you will be asked to graph your results. Some sample graphs are provided on Canvas for comparison.\n",
    "\n",
    "Adapted from a module by Prof. Glen Hocky @ NYU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#setup the notebook\n",
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "#the next things will make the default font size bigger\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "As discussed in class, the Ising model is defined by the Hamiltonian \n",
    "\n",
    "$ H = -J\\sum_{\\langle ij \\rangle}s_is_j - h\\sum_is_i $\n",
    "\n",
    "The $\\langle ij \\rangle$ indicates that the sum runs over only pairs of sites ($i$ and $j$) that are nearest neighbors on a square lattice. Here, $J$ is the coupling constant for nearest-neighbor spins, and $h$ is the magnetic field. \"Nearest neighbors\" means spins that are one lattice spacing away from the site of interest. For example, the nearest neighbors of site $(x, y)$ are the four sites $(x \\pm 1, y)$ and $(x, y \\pm 1 )$.\n",
    "\n",
    "In typical 2D Ising model simulations, a random 2D lattice of $s_i=\\pm 1$ is initialized, and then evolves by proposing possible moves and evaluating those proposals. In this case, a random spin is selected, and the spin flip (changing the spin from $-1$ to 1 or vice versa) is considered. This move is either accepted or rejected after applying an acceptance criterion (discussed later), and this process is iterated. A good proxy for \"time\" in these simulations is the Monte Carlo sweep, with one sweep being defined as $N = L^2$ proposed moves, where L is the size of the lattice, and N is therefore the total number of spins contained in the lattice. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis Criterion \n",
    "The most commonly used acceptance criterion was first proposed by Metropolis *et al.* in [this famous paper](https://aip.scitation.org/doi/10.1063/1.1699114), which is in fact *so* famous that it has its own [wikipedia article](https://en.wikipedia.org/wiki/Equation_of_State_Calculations_by_Fast_Computing_Machines)! This criterion preserves detailed balance, and allows one to evolve the system such that it samples a desired probability distribution, frequently the Boltzmann distribution. Algorithmically, this is described below. \n",
    "\n",
    "For a proposed move that takes the system from state $\\bf x$ to state $\\bf x'$, the probability of accepting that move, $P_{\\bf x,x'}$ is related to the change in energy associated with the move in the following way:\n",
    "\n",
    "$  P_{\\bf x,x'} =\n",
    "\\begin{cases}\n",
    "e^{-\\beta [E({\\bf x'})-E({\\bf x)}]},  & \\text{if $[E({\\bf x'})-E({\\bf x})] > 0$} \\\\\n",
    "1, & \\text{if $[E({\\bf x'})-E({\\bf x})] \\leq 0$}\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "where $\\beta = (k_B T)^{-1}$ is the usual inverse temperature. That is, the algorithm  always accepts moves that decrease the total energy of the system, and  only accepts some moves that increase the total energy of the system. That probability is, in this case, equal to the proportion of Boltzmann weights for the two systems. This algorithm thus samples from the Boltzmann distribution---one could change the desired distribution by changing the probability of accepting moves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodic Boundary Conditions\n",
    "\n",
    "Another typical feature of Ising model simulations is the use of periodic boundary conditions (PBCs). Most behaviors we are interested in simulating happen in bulk, but we cannot simulate an Ising model of infinite size. To address this, PBCs are implemented so that the spins on the edges of the lattice effectively \"wrap around\" and feel interactions from the spins on the opposite end of the lattice. That way, the size of the simulation is effectively extended. If you're having trouble visualizing this, google periodic boundary conditions. Or, alternatively, think about PacMan exiting from one side of the screen and re-entering from the opposite side of the screen---same deal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Typical Zero-Field 2D Ising Model Simulations\n",
    "\n",
    "So, using this information, set up a $15\\times 15$ Ising model with PBCs that evaluates proposed moves via the Metropolis criterion. We will be using this functionality for the rest of assignment, so it is best to design a flexible function that takes some input parameters (i.e., $\\beta$, $h$, dimension, number of sweeps), performs the MC iterations, and return statistics (i.e., energy, average spin, spin configuration) every sweep. Use this function to answer the following questions.\n",
    "\n",
    "1) Run these simulations for $J=1$, $h=0$, at a variety of temperatures both above and below the critical temperature. (Remember that $\\beta_C = 1/2.269 J$). Plot your energies and/or average spins as a function of MC sweeps to monitor the convergence of the system. How long do you need to simulate to get reasonable convergence of these averages/energies?  What do you notice as you approach the critical temperature? Why would that be the case? \n",
    "\n",
    "2) Visualize at least one of your Ising model trajectories near the critical temperature. This can be done a few ways, but a quick animation code snippet is included as an example. Be careful with the `%matplotlib notebook` command---you will probably want to change it back to `inline` after you're satisfied with your visualization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Coding Hints*\n",
    "\n",
    "* **Please** do not evaluate the full energy of the lattice before and after each proposed move---that is very computationally expensive. You are only proposing one spin flip at a time, so the overall change in energy should be the same as a small, local change in energy of the system directly around the proposed spin flip site. You should be able to measure the total energy of the initial system, and then update that energy after each accepted move.\n",
    "\n",
    "* A convenient way to implement PBCs is by using the modulo function, `%`\n",
    "\n",
    "* To implement the Metropolis criterion, you will need to accept a proposed move with a certain probability. You can do this by generating a random number (look at `np.random.random()`) between 0 and 1, and then comparing that number to the probability of acceptance, $P$. If $x < P$, accept the proposed move. Otherwise, reject.\n",
    "\n",
    "* Lists can be easily appended for storing data as a simulation proceeds. Converting to a numpy array can be done via `np.asarray()`\n",
    "\n",
    "* There are plenty of examples of Ising models online---if you get stuck, google it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-8e3bd8473ded>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-8e3bd8473ded>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    energy = #...\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Below are some hints as far as functions to define. You don't have to use these, but they may be helpful\n",
    "\n",
    "def energy_ising_2d(configuration,J,h):\n",
    "    #You might want to fill in this function so that it loops through the entire lattice, \n",
    "    #calculating the total energy. ONLY DO THIS ONCE per simulation\n",
    "    energy = #...\n",
    "    return energy\n",
    "\n",
    "def energy_difference(J, h, spin_value):  #Fill in extra input parameters as you see fit\n",
    "    #fill in the formula for the local energy difference from flipping spin i,\n",
    "    dE = #...\n",
    "    return dE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metropolis_mc(n_sweeps, lattice_dimension, beta, J, h):\n",
    "    #Randomly initialize the 2D lattice\n",
    "    configuration = # ...\n",
    "\n",
    "    #Find initial energy\n",
    "    n_lattice_sites = lattice_dimension**2\n",
    "    n_steps = n_sweeps*n_lattice_sites\n",
    "    current_energy = # ...\n",
    "    \n",
    "    #Loop through MC moves\n",
    "    for step_i in range(n_steps):\n",
    "        \n",
    "        #Print out statistics every sweep\n",
    "        if(step_i%n_lattice_sites==0):\n",
    "            #...\n",
    "\n",
    "        #Propose a move, and evaluate the Metropolis Criterion. Update the lattice and energy, if necessary\n",
    "        #Make sure you're including PBCs\n",
    "        #...\n",
    "        \n",
    "    #Return (for each MC sweep) the energies, average spin, and configurations. And other things if you so choose \n",
    "    return energies, average_spins, configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in your code for running the simulation itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in your code for plotting magnetization/energy vs time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the file `Ising_temps.png` for sample results from this part. Keep in mind for this, and for all other parts of this module, that randomness means your results won't agree exactly with the example. That's fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is an example script for making an animation of your configurations. This assumes that your Ising \n",
    "#configurations are in 'configurations' in the form of a 2D array. \n",
    "\n",
    "#Again, be careful with %matplotlib notebook. Make sure to reset it to inline after you're done viewing your\n",
    "#results. Things will be weird, otherwise\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib notebook\n",
    "\n",
    "fig2 = plt.figure()\n",
    "\n",
    "ims = []\n",
    "for conf in configurations:\n",
    "    ims.append((plt.pcolor(conf),))\n",
    "\n",
    "im_ani = animation.ArtistAnimation(fig2, ims, interval=50, repeat_delay=3000,\n",
    "                                   blit=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part 2 - Critical Exponents in the Zero-Field 2D Ising Model\n",
    "\n",
    "As you learned in class, phase transitions can be described by various [critical exponents](https://en.wikipedia.org/wiki/Critical_exponent) for observables like the average magnetization, magentic susceptibility, and heat capacity. These critical exponents have been studied specifically for [Ising models](https://en.wikipedia.org/wiki/Ising_critical_exponents)---we will investigate these exponents in this part of the module. Make sure you read both of these links and consult your notes, as they will be useful for this section.\n",
    "\n",
    "Run 5 simulations ($J=1, h=0$) for each $\\beta$ value in a range that goes from above to below the critical temperature. The $\\beta$ range is up to you, but you want data both near the transition temperature and in the regime where either the ordered or disorded phase dominates. A reasonable choice is ten $\\beta$ values between 0.2 and 0.6, but you are encouraged to explore alternatives. You may want to gather some preliminary data, and then go back and edit your range to more clearly define the regions/slopes of interest. Use these data to answer the following questions:\n",
    "\n",
    "1) From your simulations, find the average absolute magnetization (average spin in the lattice, $|m|$---the absolute value is taken to control for the symmetry between all $-1$ spins and all 1 spins) for your chosen $\\beta$ range. Graph this (and the associated standard deviations as error bars---check `plt.errorbar()` ) for both a $15\\times 15$ and a $20\\times 20$ lattice. Also graph this in terms of the reduced temperature $\\epsilon = (T - T_C)/T_C$. Briefly explain the trends you see in these graphs.\n",
    "\n",
    "2) Plot the net magnetization against reduced temperature on a log-log plot in order to extract the critical exponent from the slope. You will have to limit the data points to those  in the ordered regime---check the definition of this critical exponent $\\beta$ (not to be confused with the inverse temperature). What values of the critical exponent do you obtain? How does it compare to the analytical result of $\\beta$ = 0.125? `np.polyfit()` might be useful here. Comment on the size and direction of the error due to finite size effects.\n",
    "\n",
    "3) Repeat this procedure for both the per spin magnetic susceptibility and heat capacity, obtaining the critical exponents $\\gamma$ and $\\alpha$, respectively. It may take a bit of thinking, but you should be able to get this information from your simulations, assuming you output the energies and magnetizations of your simulations for every Monte Carlo sweep. *Hint*: How are these quantities related to energy and magnetization fluctuations? Also note that for the critical exponent step, now you have to limit the data points to those in the disordered regime.\n",
    "\n",
    "*Note:* Remember that you are starting your simulation out of equilibrium, in a random initialization. Thus, when calculating averages, you will want to discard some of the sampling from each trajectory and use only the equilibrium part of the sampling. Furthermore, feel free to graph the heat capacity $C_V$ in units of $k_B$, which will make it so you don't have to choose a particular unit system. If you are not satisfied with the critical exponents you obtain by using this method, feel free to also try the size rescaling approach found in Section 2.4 of [this paper](https://arxiv.org/pdf/0803.0217.pdf). In this approach, you find the critical exponents by varying the size of the Ising model itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in your code for running your simulations at a variety of temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use something like this to plot your results (filling in extra info where needed), \n",
    "#repeating for each of the three sublots\n",
    "f, ax = plt.subplots(1,3, figsize = (20,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "ax[0].plot()  #Plot both the 15x15 and the 20x20 results\n",
    "ax[0].plot()\n",
    "ax[0].set_ylabel()\n",
    "ax[0].set_xlabel()\n",
    "ax[0].axvline()  #Label the critical temperature\n",
    "ax[0].legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#I have example graphs for each of the questions asked - feel free to compare, but again don't expect the \n",
    "#same results. Random fluctations here will be fairly large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, make sure to check the example graphs on Canvas for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Studying the finite-field Ising model using Umbrella Sampling\n",
    "\n",
    "As you (probably) learned last quarter, Umbrella Sampling (US) can be used  to compute the potential of mean force (PMF, if unfamiliar, read Chandler's *Introduction to Modern Statistical Mechanics* pg. 169-175) efficiently. In this case, we want to compute the probability of seeing a particular value of $m$, including rare values of $m$, at a particular $J$ and $h$. For now, let's look at $\\beta = 0.2, h = 0.9$ on a $20\\times 20$ lattice. \n",
    "\n",
    "We will be implementing a \"hard wall\" version of US. Specifically, this means that we will run a range of simulations that are restricted to only sample a certain area of parameter space, in this case magnetization $m$. A common alternative is to introduce harmonic biasing functions, which results in faster suppression of window boundary effects.\n",
    "\n",
    "For each simulation, you will generate a starting configuration within the allowed \"window,\" $m_i \\pm \\delta$, and then evolve the system as normal. The only difference from what we did before is that now any proposed configuration outside of $m_i \\pm \\delta$ has an infinite energy. As a result, copies of the system can be forced to sample high-energy, low-probability areas of parameter space. We can then combine all of the data, account for the biases introduced, and stitch the results together to obtain the unbiased PMF. For the hard wall US, accounting for the applied biases simply means making sure the PMF is continuous.\n",
    "More general and sophisticated schemes for combining the data exist: the Weighted Histogram Analysis Method ([WHAM](http://www.alchemistry.org/wiki/Weighted_Histogram_Analysis_Method)) and the Eigenvector Method for Umbrella Sampling ([EMUS](https://aip.scitation.org/doi/10.1063/1.4960649)), as examples.\n",
    "\n",
    "For now, modify your Ising model from above to run this type of US simulation, controlling the sampling of the magnetization $m$ (no absolute value). You should first make sure you can generate an initial configuration inside your desired window of $m$ to be simulated, and then evolve the system using the Metropolis criterion,  rejecting any moves that take the configuration outside of $m_i \\pm \\delta$. A reasonable starting point is to use 7 windows between $m=0.2$ and $m=0.8$ (using $\\delta = 0.05$), but you can vary this to try to improve the sampling. For each window, run at least 5 simulations of 500 sweeps each, saving the magnetization trajectories from each. From there, histogram your magnetizations in each window, and convert those histogram counts into a PMF. Stitch together your PMF to make it continuous, and shift the minimum to 0. \n",
    "\n",
    "1) Graph both your PMF and your associated normalized probability to show the free energy and probability associated with a range of magnetization values when $\\beta = 0.2, h = 0.9$. What is the most likely magnetization value for this set of parameters? Why is this the case? How do you think your answer would change as you increased $h$? As you increased temperature? You are encouranged to perform simulations for these other conditions, but it is not required for the assignment.     \n",
    "\n",
    "2) Do the same thing, but now with $\\beta = 0.5, h=0.01$. Rationalize what you see. What would happen if you tried to make a similar PMF graph, but without having any biasing potentials---i.e., just running at equilibrium? \n",
    "\n",
    "*Note:* `np.histogram` will prove useful for this part of the module. You also will likely end up having many bins with counts = 0, which can prove tricky when taking a logarithm to find the PMF. In this case, `np.nonzero` might also be useful. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_window(target, delta, lattice_dimension):\n",
    "    #Define some function that initializes a specific configuration that is within each window of interest. \n",
    "    #There are many ways to do this - choose your favorite. \n",
    "    \n",
    "    return init_config, init_magnetization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metropolis_mc_umbrella(n_sweeps, lattice_dimension, beta, J, h, m_i, delta):\n",
    "    \n",
    "    #Similar to before, but make sure that you are initializing correctly, and that you are applying the\n",
    "    #bias associated with your windows.\n",
    "    return energies, average_spins, configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in your code for running the simulations for each window (Question 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in your graphing code (Question 1)\n",
    "#Histogram your trajectories, transform them into a piecewise PMF, and then stitch them together to make \n",
    "#the PMF continuous. Then make this into a probability distribution. \n",
    "#Example graphs of each step of this process are available for you to compare with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in your code for running simulations for each window (Question 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill in your graphing code (Question 2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
